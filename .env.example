# Main Agent Configuration (Coordinator)
# Use a more powerful model for complex reasoning and coordination
# Groq Llama 70B for main agent
MAIN_MODEL_NAME=llama-3.3-70b-versatile
MAIN_MODEL_BASE_URL=https://api.groq.com/openai/v1/chat/completions

# Sub-Agent Configuration (Focused Tasks)
# Use a less powerful/cheaper model for simple, focused tasks
# Groq Llama 8B for sub-agents (faster and cheaper)
SUB_AGENT_MODEL_NAME=llama-3.1-8b-instant
SUB_AGENT_MODEL_BASE_URL=https://api.groq.com/openai/v1/chat/completions

# Groq API Key (used for both main and sub-agents)
GROQ_API_KEY=your_groq_api_key_here

# Alternative: Use OpenAI models
# MAIN_MODEL_NAME=gpt-4o-mini
# MAIN_MODEL_BASE_URL=https://api.openai.com/v1/chat/completions
# SUB_AGENT_MODEL_NAME=gpt-3.5-turbo
# SUB_AGENT_MODEL_BASE_URL=https://api.openai.com/v1/chat/completions
# OPENAI_API_KEY=your_openai_api_key_here

# Alternative: Use local Ollama for sub-agents with Groq for main
# MAIN_MODEL_NAME=llama-3.3-70b-versatile
# MAIN_MODEL_BASE_URL=https://api.groq.com/openai/v1/chat/completions
# GROQ_API_KEY=your_groq_api_key_here
# SUB_AGENT_MODEL_NAME=llama3:8b
# SUB_AGENT_MODEL_BASE_URL=http://localhost:11434/v1/chat/completions

# Alternative: Use same Groq API key for both models
# SUB_AGENT_MODEL_API_KEY=${MAIN_MODEL_API_KEY}

# General Configuration
MAX_LOOP_COUNT=20
MAX_CONTEXT_CHARACTERS=15000

# Legacy environment variables (for backwards compatibility)
# If MAIN_MODEL_* is not set, these will be used as fallbacks
MODEL_NAME=llama3:8b
MODEL_BASE_URL=http://localhost:11434/v1/chat/completions
OPENAI_API_KEY=
